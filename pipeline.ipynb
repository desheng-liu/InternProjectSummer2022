{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import kfp\n",
    "import kfp.components as comp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.v2.dsl\n",
    "\n",
    "import kfp_tekton\n",
    "from kfp_tekton import k8s_client_helper\n",
    "\n",
    "from kubernetes.client.models import V1EnvVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"tf_spacenet_cv_classify_pipeline-e426805\"\n",
    "PIPELINE_PACKAGE = f\"{PIPELINE_NAME}.zip\"\n",
    "EXPERIMENT_NAME = \"RMS ET Intern Project\"\n",
    "PERSISTENT_VOLUME_CLAIM_NAME = \"rms-et-sn-pvc\"\n",
    "\n",
    "KUBEFLOW_PUBLIC_ENDPOINT_URL = \"https://kubeflow.apps.pcell.ai.us.lmco.com\"\n",
    "SESSION_COOKIE = \"authservice_session=MTY1ODI1NDM2NXxOd3dBTkZOUVNrWlBOakkyVEZGYVJrODFVVlZOUlVKUldsRktUek5JUjBsUFNqUllTMDlMUkVaVVFWQkxRbFJLVEZrMFFWbEZOMEU9fE7AOJaxj2kgkesMohGGCXqQKN6pQzrkJYEkzHuciy5u\"\n",
    "KUBEFLOW_PROFILE_NAME = \"kf-rms-et-intern-project-17\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component\n",
    "def view_data():\n",
    "    import json\n",
    "    import os\n",
    "    import logging\n",
    "    \n",
    "    DATASET_PATH = \"/data/V1/sn1_AOI_1_RIO/sn1_AOI_1_RIO/sn1_AOI_1_RIO/\"\n",
    "    \n",
    "    PATH_TO_COLLECTION_FILE=os.path.join(DATASET_PATH, 'collection.json')\n",
    "\n",
    "    with open(PATH_TO_COLLECTION_FILE, 'r') as f:\n",
    "        collection_json = json.load(f)\n",
    "\n",
    "    print(f\"collection_json top level keys: {collection_json.keys()}\\n\")\n",
    "    print(f\"description: {collection_json['description']}\")\n",
    "    \n",
    "    def limit_string(s, chars=200):\n",
    "        s = str(s)\n",
    "        len_to_print = max(min(len(s), chars), 1)\n",
    "        return s[0:len_to_print]\n",
    "    \n",
    "    [print(f\"{k} : {limit_string(collection_json[k])}\") for k in collection_json.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_data_op = comp.func_to_container_op(\n",
    "    view_data,\n",
    "    base_image=\"harbor.ai.us.lmco.com/ai-factory-local/internal/aws-cli:1.20.58-debian-10-r2-0\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component\n",
    "def predict():\n",
    "    import datetime\n",
    "    import json\n",
    "    import os\n",
    "    import math\n",
    "    import random\n",
    "    \n",
    "    # for dataset\n",
    "    import torch\n",
    "    import numpy as np\n",
    "\n",
    "    # Python Image Library can \n",
    "    # load tiffs and convert to numpy arrays\n",
    "    from PIL import Image\n",
    "    from IPython.display import display\n",
    "\n",
    "    # for mask creation based on geospatial data\n",
    "    import fiona\n",
    "    import rioxarray\n",
    "    import geojson\n",
    "\n",
    "    from pathlib import Path\n",
    "    # import UNet Model Configuration, UNet Vision Model Configuration, and the Vision Model\n",
    "    import classification as lmclassification\n",
    "    from classification.data_types.network_callbacks.checkpoint_callback import CheckPointCallback as CheckpointCallback\n",
    "    from classification.network_models.configurations.unet_model_configuration import UNetModelConfiguration as ModelConfiguration\n",
    "    from classification.vision.models.configurations.unet_vision_model_configuration import UNetVisionModelConfiguration as VisionModelConfiguration\n",
    "    from classification.vision.models.unet_vision_model import UNetVisionModel as Model\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    import matplotlib.colors as colors\n",
    "    \n",
    "    class SpaceNetDataset(torch.utils.data.Dataset):\n",
    "        \"\"\"\n",
    "        A torch.utils.data.Dataset wrapping the SpaceNet Building Detection V1 dataset\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, path_to_collection, *args, **kwargs):\n",
    "            \"\"\"\n",
    "            Construct the dataset\n",
    "\n",
    "            Provide any information required to allow subsequent operation\n",
    "            \"\"\"\n",
    "\n",
    "            if not isinstance(path_to_collection, Path):\n",
    "                path_to_collection = Path(path_to_collection)\n",
    "\n",
    "            self.path_to_collection = path_to_collection\n",
    "            self.collection_dir = os.path.dirname(path_to_collection)\n",
    "\n",
    "            with open(self.path_to_collection, 'r') as f:\n",
    "                self.collection = json.load(f)\n",
    "\n",
    "            # self.links holds all the top level folders\n",
    "            # filter out the ones that end with -labels since we know \n",
    "            # there will be a corresponding non-labels folder\n",
    "            self.links = [x[\"href\"] for x in self.collection[\"links\"] if not os.path.dirname(x[\"href\"]).endswith('-labels') ]\n",
    "\n",
    "        def __len__(self) -> int:\n",
    "            \"\"\"\n",
    "            Returns:\n",
    "                The length of the whole dataset to load\n",
    "            \"\"\"\n",
    "            return len(self.links)\n",
    "\n",
    "        def __getitem__(self, idx) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n",
    "            \"\"\"\n",
    "            Given an index, provide the training example at that index\n",
    "\n",
    "            To satisfy the CCM return a tuple of 2 elements:\n",
    "                The first element is a numpy np.ndarray, 32-bit or 64-bit float, with shape (channels, pixel height, pixel width)\n",
    "                The second element is a dictionary.\n",
    "                    The only required key is 'masks'\n",
    "                    The 'masks' key must map to a numpy np.ndarray, 64-bit integers, with shape (classes, pixel height, pixel width)\n",
    "                    In this case the classes are background and building (just 2 classes)\n",
    "                    For the background class, pixel locations that are background should be set to 1, otherwise 0\n",
    "                    For the building class, pixel locations that are buildings should be set to 1, otherwise 0\n",
    "                    Image values in the numpy ndarray should be normalized to a range from 0.0 to 1.0\n",
    "\n",
    "            Other requirements:\n",
    "                Image Width must be the same as Segmentation Mask Width\n",
    "                Image Height must be the same as Segmentation Mask Height\n",
    "\n",
    "                If no features are present. the mask should still exist but take on default values, eg\n",
    "                    background class all ones\n",
    "                    building class all zeros\n",
    "                    other constraints are still enforced\n",
    "\n",
    "            Args:\n",
    "                index into the dataset to sample\n",
    "\n",
    "            Returns:\n",
    "                The dataset example at a given index in the form of a tuple of\n",
    "                np.ndarray and dictionary of string key mapped to np.ndarrays\n",
    "            \"\"\"\n",
    "\n",
    "            # index into folders\n",
    "            example_file = self.links[idx]\n",
    "\n",
    "            # construct the known corresponding label folder name\n",
    "            label_folder = f\"{os.path.dirname(example_file)}-labels\"\n",
    "\n",
    "            # construct the relative path to the \"stac.json file\"\n",
    "            label_file = os.path.join(label_folder, 'stac.json')\n",
    "\n",
    "            with open(os.path.join(self.collection_dir, example_file), 'r') as f:\n",
    "                example_json = json.load(f)\n",
    "\n",
    "            # construct the path to the image file\n",
    "            image_file = os.path.join(self.collection_dir, os.path.dirname(example_file), example_json[\"assets\"][\"RGB\"][\"href\"])\n",
    "\n",
    "            with open(os.path.join(self.collection_dir, label_file), 'r') as f:\n",
    "                labels_json = json.load(f)\n",
    "\n",
    "            # construct the paths to the labels file\n",
    "            label_file = os.path.join(self.collection_dir, label_folder, labels_json[\"assets\"][\"labels\"][\"href\"])\n",
    "\n",
    "            # load the .tif image from disk\n",
    "            pil_img = Image.open(image_file)\n",
    "\n",
    "            # convert the PIL image to a numpy array\n",
    "            img = np.array(pil_img)\n",
    "\n",
    "            # normalize from 0.0 to 1.0\n",
    "            img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "            # open with fiona to get features for mask - this represnts the buildings\n",
    "            with fiona.open(label_file, 'r') as f:\n",
    "                features = [feature[\"geometry\"] for feature in f]\n",
    "\n",
    "            # create the rasterizer object based on the image data\n",
    "            rds = rioxarray.open_rasterio(image_file).isel(band=0)\n",
    "\n",
    "            # get the geojson data\n",
    "            with open(label_file) as igj:\n",
    "                data = geojson.load(igj)\n",
    "\n",
    "            # binary crossentropy requires masks of shape (2, height, width)\n",
    "            # the first channel represnts classes; 0=background, 1=building\n",
    "            mask = np.zeros((2, *img.shape[0:2])).astype(np.int64)\n",
    "            mask[0,:,:] = np.ones((1, *img.shape[0:2])) # background by default\n",
    "\n",
    "            # if this training/validation example has features (building masks)\n",
    "            if len(features) > 0:\n",
    "\n",
    "                # get the mask - binary cross entropy\n",
    "                rds = rds.rio.clip(features, data[\"crs\"][\"properties\"][\"name\"], drop=False)\n",
    "                nprds = np.array(rds)\n",
    "\n",
    "                mask[0, :, :] = np.where((nprds)>0.5, 0, mask[0, :, :])\n",
    "                mask[1, :, :] = np.where(nprds>0.5, 1, mask[1, :, :])\n",
    "\n",
    "            # if the example did not have features, leave the images and masks as they were\n",
    "\n",
    "            # channels, height, width\n",
    "            img = np.transpose(img,  (2, 0, 1))\n",
    "\n",
    "            # clip both masks and images to ensure they are the same size\n",
    "            # otherwise CCM / Most Conv networks will not accept\n",
    "            min_height = min(img.shape[1], mask.shape[1])\n",
    "            min_width  = min(img.shape[2], mask.shape[2])\n",
    "            img = img[:, :min_height, :min_width]\n",
    "            mask = mask[:, :min_height, :min_width]\n",
    "            mask = np.expand_dims(np.argmax(mask, axis=0), axis=0)\n",
    "\n",
    "            # CCM vision models expect targets to be in a dictionary \n",
    "            # other keys for other types of computer vision problems include\n",
    "            # 'boxes' and 'labels'. UNet does not require those\n",
    "            return img, {'masks': mask}\n",
    "    \n",
    "    # Instantiate the Dataloader\n",
    "    DATASET_PATH = \"/data/V1/sn1_AOI_1_RIO/sn1_AOI_1_RIO/sn1_AOI_1_RIO/\"\n",
    "    PATH_TO_COLLECTION_FILE=os.path.join(DATASET_PATH, 'collection.json')\n",
    "    dataset = SpaceNetDataset(PATH_TO_COLLECTION_FILE)\n",
    "    \n",
    "    TRAIN_SPLIT = 0.7\n",
    "    TEST_SPLIT = 0.3\n",
    "\n",
    "    print(f\"TRAINING SPLIT STARTED\")\n",
    "    \n",
    "    test_dataset, train_dataset = torch.utils.data.random_split(\n",
    "        dataset, \n",
    "        [math.floor(TEST_SPLIT*len(dataset)), math.ceil(TRAIN_SPLIT*len(dataset)) ],\n",
    "        generator=torch.Generator().manual_seed(1234)\n",
    "    )\n",
    "    \n",
    "    print(f\"TRAINING SPLIT FINISHED\")\n",
    "    \n",
    "    # instantiate UNet Model Configuration\n",
    "    config = ModelConfiguration()\n",
    "    \n",
    "    # instantiate UNet Vision Model Configuration\n",
    "    model_config = VisionModelConfiguration(\n",
    "        input_shape=(480,480),\n",
    "        n_classes=2,\n",
    "        input_channels=3,\n",
    "        batch_size=6,\n",
    "        learning_rate=1e-4,\n",
    "        validation_split=0.3,\n",
    "        training_epochs=11,\n",
    "        layers_model_configuration=config,\n",
    "    )\n",
    "    # ensure we allow for the background class and building class\n",
    "    # RGB    \n",
    "    # during testing x% of the training dataset will be reserved for validation\n",
    "\n",
    "\n",
    "    # Instantiate UNet\n",
    "    model = Model(model_config)\n",
    "\n",
    "        # if using pretrained weights, Images should be renormalized according to pytorch's specification:\n",
    "        #    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                                     std=[0.229, 0.224, 0.225])\n",
    "        # see https://gitlab.us.lmco.com/overwatch/cognitive-modules/classification/-/blob/master/examples/jupyter_notebooks/supervised_examples/deep_learning_examples/inception_v3_classifier_example.ipynb\n",
    "        #         Create Classes and Labels from Dataset \n",
    "   \n",
    "    nowstr = datetime.datetime.now().strftime('%m%d%Y_%H%M%S')\n",
    "    model_path = f'./mnt/space_net_models/trained_spacenet_{nowstr}.pt'\n",
    "    print(f\"training new model: {model_path}\")\n",
    "    model_save_path = model_path\n",
    "    checkpoint_path = './mnt/space_net_models/'\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "    # train the model!\n",
    "    results = model.fit(train_dataset, verbose=True, callbacks=[CheckpointCallback(checkpoint_path)])\n",
    "\n",
    "    # save the trained model for the epochs configured\n",
    "    model.save_model(model_save_path)\n",
    "    print(f\"saving model to: {model_save_path} \\n\") \n",
    "    \n",
    "    # load the trained model\n",
    "    model.load_model(model_save_path)\n",
    "    \n",
    "    # load a test example\n",
    "    img, mask = test_dataset[ random.randint(0, len(test_dataset)) ]\n",
    "    \n",
    "    # run model inference\n",
    "    results = model.infer([img])\n",
    "    \n",
    "    result_mask = results[0]['masks']\n",
    "\n",
    "    result_mask = (result_mask - result_mask.min()) / (result_mask.max()-result_mask.min())\n",
    "\n",
    "    print(\"******** Inference Results ********\")\n",
    "    print(f\"Overall minimum prediction confidence = {result_mask.min()}\")\n",
    "    print(f\"Overall maximum prediction confidence = {result_mask.max()}\")\n",
    "    print(f\"Overall mean prediction confidence = {result_mask.mean()} \\n\")\n",
    "    \n",
    "    print(f\"Minimum Building prediction confidence = {result_mask[1,:,:].min()}\")\n",
    "    print(f\"Maximum Building prediction confidence = {result_mask[1,:,:].max()}\")\n",
    "    print(f\"Mean Building prediction confidence = {result_mask[1,:,:].mean()} \\n\")\n",
    "    \n",
    "    print(f\"Minimum Background prediction confidence = {result_mask[0,:,:].min()}\")\n",
    "    print(f\"Maximum Background prediction confidence = {result_mask[0,:,:].max()}\")\n",
    "    print(f\"Mean Background prediction confidence = {result_mask[0,:,:].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_op = comp.func_to_container_op(\n",
    "    predict,\n",
    "    base_image=\"harbor.ai.us.lmco.com/ai-factory-local/pytorch:1.8.1-cuda11.1-cudnn8-runtime-4\",\n",
    "    packages_to_install=['urllib3==1.25.8','fiona','numpy','Pillow','geojson', 'rioxarray', 'lm-ai-classification', 'matplotlib', 'sklearn']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=PIPELINE_NAME,\n",
    "    description=EXPERIMENT_NAME\n",
    ")\n",
    "def rms_et_basic_pipeline():\n",
    "    view_data_r = (\n",
    "        view_data_op()\n",
    "        .add_pvolumes({\"/data\": dsl.PipelineVolume(pvc=\"spacenet-data\")})\n",
    "    )\n",
    "    predict_r = (\n",
    "        predict_op()\n",
    "        .set_gpu_limit(8)\n",
    "        .add_env_variable(k8s_client_helper.env_from_secret(\"PIP_EXTRA_INDEX_URL\", \"nexus-config\", \"PIP_EXTRA_INDEX_URL\"))\n",
    "        .add_env_variable(k8s_client_helper.env_from_secret(\"PIP_INDEX_URL\", \"nexus-config\", \"PIP_INDEX_URL\"))\n",
    "        .add_pvolumes({\"/data\": dsl.PipelineVolume(pvc=\"spacenet-data\")})\n",
    "        .after(view_data_r)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
"outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://kubeflow.apps.pcell.ai.us.lmco.com/pipeline/#/runs/details/b603b3b1-7170-4efa-bf87-828a45a91e3f\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2022, 7, 20, 14, 40, 15, tzinfo=tzlocal()),\n",
       " 'description': None,\n",
       " 'error': None,\n",
       " 'finished_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
       " 'id': 'b603b3b1-7170-4efa-bf87-828a45a91e3f',\n",
       " 'metrics': None,\n",
       " 'name': 'tf_spacenet_cv_classify_pipeline-e426805 2022-07-20T14:40:15.661785',\n",
       " 'pipeline_spec': {'parameters': None,\n",
       "                   'pipeline_id': 'c4011637-61c2-4e2d-b0e0-686480df65cf',\n",
       "                   'pipeline_manifest': None,\n",
       "                   'pipeline_name': 'tf_spacenet_cv_classify_pipeline-e426805',\n",
       "                   'runtime_config': None,\n",
       "                   'workflow_manifest': '{\"kind\":\"PipelineRun\",\"apiVersion\":\"tekton.dev/v1beta1\",\"metadata\":{\"name\":\"tf-spacenet-cv-classify-pipeline-e426805\",\"creationTimestamp\":null,\"annotations\":{\"pipelines.kubeflow.org/big_data_passing_format\":\"$(workspaces.$TASK_NAME.path)/artifacts/$ORIG_PR_NAME/$TASKRUN_NAME/$TASK_PARAM_NAME\",\"pipelines.kubeflow.org/pipeline_spec\":\"{\\\\\"description\\\\\": '\n",
       "                                        '\\\\\"RMS ET Intern Project\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"tf_spacenet_cv_classify_pipeline-e426805\\\\\"}\",\"sidecar.istio.io/inject\":\"false\",\"tekton.dev/artifact_bucket\":\"mlpipeline\",\"tekton.dev/artifact_endpoint\":\"minio-service.kubeflow:9000\",\"tekton.dev/artifact_endpoint_scheme\":\"http://\",\"tekton.dev/artifact_items\":\"{\\\\\"predict\\\\\": '\n",
       "                                        '[], \\\\\"view-data\\\\\": '\n",
       "                                        '[]}\",\"tekton.dev/input_artifacts\":\"{}\",\"tekton.dev/output_artifacts\":\"{}\"}},\"spec\":{\"pipelineSpec\":{\"tasks\":[{\"name\":\"view-data\",\"taskSpec\":{\"spec\":null,\"metadata\":{\"labels\":{\"pipelines.kubeflow.org/cache_enabled\":\"true\",\"pipelines.kubeflow.org/generation\":\"\",\"pipelines.kubeflow.org/pipelinename\":\"\"},\"annotations\":{\"pipelines.kubeflow.org/component_spec_digest\":\"{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"View data\\\\\", \\\\\"outputs\\\\\": [], '\n",
       "                                        '\\\\\"version\\\\\": \\\\\"View '\n",
       "                                        'data@sha256=e64d4b83885b76b8dfcfae7c56706e5f4e9b55ed6e7cc43011ad1a5223a3012e\\\\\"}\",\"tekton.dev/template\":\"\"}},\"steps\":[{\"name\":\"main\",\"image\":\"harbor.ai.us.lmco.com/ai-factory-local/internal/aws-cli:1.20.58-debian-10-r2-0\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        'view_data():\\\\n    import json\\\\n    '\n",
       "                                        'import os\\\\n    import '\n",
       "                                        'logging\\\\n\\\\n    DATASET_PATH = '\n",
       "                                        '\\\\\"/data/V1/sn1_AOI_1_RIO/sn1_AOI_1_RIO/sn1_AOI_1_RIO/\\\\\"\\\\n\\\\n    '\n",
       "                                        'PATH_TO_COLLECTION_FILE=os.path.join(DATASET_PATH, '\n",
       "                                        \"'collection.json')\\\\n\\\\n    with \"\n",
       "                                        \"open(PATH_TO_COLLECTION_FILE, 'r') as \"\n",
       "                                        'f:\\\\n        collection_json = '\n",
       "                                        'json.load(f)\\\\n\\\\n    '\n",
       "                                        'print(f\\\\\"collection_json top level '\n",
       "                                        'keys: '\n",
       "                                        '{collection_json.keys()}\\\\\\\\n\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"description: '\n",
       "                                        '{collection_json[\\'description\\']}\\\\\")\\\\n\\\\n    '\n",
       "                                        'def limit_string(s, '\n",
       "                                        'chars=200):\\\\n        s = '\n",
       "                                        'str(s)\\\\n        len_to_print = '\n",
       "                                        'max(min(len(s), chars), 1)\\\\n        '\n",
       "                                        'return s[0:len_to_print]\\\\n\\\\n    '\n",
       "                                        '[print(f\\\\\"{k} : '\n",
       "                                        '{limit_string(collection_json[k])}\\\\\") '\n",
       "                                        'for k in '\n",
       "                                        'collection_json.keys()]\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='View \"\n",
       "                                        \"data', description='')\\\\n_parsed_args \"\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'view_data(**_parsed_args)\\\\n\"],\"resources\":{},\"volumeMounts\":[{\"name\":\"pvolume-e08f34d8bcb983a9b9b9689d664304a9fe46292eb114fc9f83031d4\",\"mountPath\":\"/data\"}]}],\"volumes\":[{\"name\":\"pvolume-e08f34d8bcb983a9b9b9689d664304a9fe46292eb114fc9f83031d4\",\"persistentVolumeClaim\":{\"claimName\":\"spacenet-data\"}}]},\"timeout\":\"8760h0m0s\"},{\"name\":\"predict\",\"taskSpec\":{\"spec\":null,\"metadata\":{\"labels\":{\"pipelines.kubeflow.org/cache_enabled\":\"true\",\"pipelines.kubeflow.org/generation\":\"\",\"pipelines.kubeflow.org/pipelinename\":\"\"},\"annotations\":{\"pipelines.kubeflow.org/component_spec_digest\":\"{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"Predict\\\\\", \\\\\"outputs\\\\\": [], '\n",
       "                                        '\\\\\"version\\\\\": '\n",
       "                                        '\\\\\"Predict@sha256=73efc1fad0c8c7671c0b1973342541dba0f529d63f3615b16dbff50f58b3cf58\\\\\"}\",\"tekton.dev/template\":\"\"}},\"steps\":[{\"name\":\"main\",\"image\":\"harbor.ai.us.lmco.com/ai-factory-local/pytorch:1.8.1-cuda11.1-cudnn8-runtime-4\",\"command\":[\"sh\",\"-c\",\"(PIP_DISABLE_PIP_VERSION_CHECK=1 '\n",
       "                                        'python3 -m pip install --quiet '\n",
       "                                        '--no-warn-script-location '\n",
       "                                        \"'urllib3==1.25.8' 'fiona' 'numpy' \"\n",
       "                                        \"'Pillow' 'geojson' 'rioxarray' \"\n",
       "                                        \"'lm-ai-classification' 'matplotlib' \"\n",
       "                                        \"'sklearn' || \"\n",
       "                                        'PIP_DISABLE_PIP_VERSION_CHECK=1 '\n",
       "                                        'python3 -m pip install --quiet '\n",
       "                                        '--no-warn-script-location '\n",
       "                                        \"'urllib3==1.25.8' 'fiona' 'numpy' \"\n",
       "                                        \"'Pillow' 'geojson' 'rioxarray' \"\n",
       "                                        \"'lm-ai-classification' 'matplotlib' \"\n",
       "                                        \"'sklearn' --user) \\\\u0026\\\\u0026 \"\n",
       "                                        '\\\\\"$0\\\\\" '\n",
       "                                        '\\\\\"$@\\\\\"\",\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        'predict():\\\\n    import '\n",
       "                                        'datetime\\\\n    import json\\\\n    '\n",
       "                                        'import os\\\\n    import math\\\\n    '\n",
       "                                        'import random\\\\n\\\\n    # for '\n",
       "                                        'dataset\\\\n    import torch\\\\n    '\n",
       "                                        'import numpy as np\\\\n\\\\n    # Python '\n",
       "                                        'Image Library can \\\\n    # load tiffs '\n",
       "                                        'and convert to numpy arrays\\\\n    '\n",
       "                                        'from PIL import Image\\\\n    from '\n",
       "                                        'IPython.display import '\n",
       "                                        'display\\\\n\\\\n    # for mask creation '\n",
       "                                        'based on geospatial data\\\\n    import '\n",
       "                                        'fiona\\\\n    import rioxarray\\\\n    '\n",
       "                                        'import geojson\\\\n\\\\n    from pathlib '\n",
       "                                        'import Path\\\\n    # import UNet Model '\n",
       "                                        'Configuration, UNet Vision Model '\n",
       "                                        'Configuration, and the Vision '\n",
       "                                        'Model\\\\n    import classification as '\n",
       "                                        'lmclassification\\\\n    from '\n",
       "                                        'classification.data_types.network_callbacks.checkpoint_callback '\n",
       "                                        'import CheckPointCallback as '\n",
       "                                        'CheckpointCallback\\\\n    from '\n",
       "                                        'classification.network_models.configurations.unet_model_configuration '\n",
       "                                        'import UNetModelConfiguration as '\n",
       "                                        'ModelConfiguration\\\\n    from '\n",
       "                                        'classification.vision.models.configurations.unet_vision_model_configuration '\n",
       "                                        'import UNetVisionModelConfiguration '\n",
       "                                        'as VisionModelConfiguration\\\\n    '\n",
       "                                        'from '\n",
       "                                        'classification.vision.models.unet_vision_model '\n",
       "                                        'import UNetVisionModel as '\n",
       "                                        'Model\\\\n\\\\n    import '\n",
       "                                        'matplotlib.pyplot as plt\\\\n    import '\n",
       "                                        'matplotlib.patches as patches\\\\n    '\n",
       "                                        'import matplotlib.colors as '\n",
       "                                        'colors\\\\n\\\\n    class '\n",
       "                                        'SpaceNetDataset(torch.utils.data.Dataset):\\\\n        '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n        A '\n",
       "                                        'torch.utils.data.Dataset wrapping the '\n",
       "                                        'SpaceNet Building Detection V1 '\n",
       "                                        'dataset\\\\n        '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n\\\\n        def '\n",
       "                                        '__init__(self, path_to_collection, '\n",
       "                                        '*args, **kwargs):\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n            Construct the '\n",
       "                                        'dataset\\\\n\\\\n            Provide any '\n",
       "                                        'information required to allow '\n",
       "                                        'subsequent operation\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n\\\\n            if not '\n",
       "                                        'isinstance(path_to_collection, '\n",
       "                                        'Path):\\\\n                '\n",
       "                                        'path_to_collection = '\n",
       "                                        'Path(path_to_collection)\\\\n\\\\n            '\n",
       "                                        'self.path_to_collection = '\n",
       "                                        'path_to_collection\\\\n            '\n",
       "                                        'self.collection_dir = '\n",
       "                                        'os.path.dirname(path_to_collection)\\\\n\\\\n            '\n",
       "                                        'with open(self.path_to_collection, '\n",
       "                                        \"'r') as f:\\\\n                \"\n",
       "                                        'self.collection = '\n",
       "                                        'json.load(f)\\\\n\\\\n            # '\n",
       "                                        'self.links holds all the top level '\n",
       "                                        'folders\\\\n            # filter out '\n",
       "                                        'the ones that end with -labels since '\n",
       "                                        'we know \\\\n            # there will '\n",
       "                                        'be a corresponding non-labels '\n",
       "                                        'folder\\\\n            self.links = '\n",
       "                                        '[x[\\\\\"href\\\\\"] for x in '\n",
       "                                        'self.collection[\\\\\"links\\\\\"] if not '\n",
       "                                        'os.path.dirname(x[\\\\\"href\\\\\"]).endswith(\\'-labels\\') '\n",
       "                                        ']\\\\n\\\\n        def '\n",
       "                                        '__len__(self):\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n            '\n",
       "                                        'Returns:\\\\n                The length '\n",
       "                                        'of the whole dataset to '\n",
       "                                        'load\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n            return '\n",
       "                                        'len(self.links)\\\\n\\\\n        def '\n",
       "                                        '__getitem__(self, idx):\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n            Given an '\n",
       "                                        'index, provide the training example '\n",
       "                                        'at that index\\\\n\\\\n            To '\n",
       "                                        'satisfy the CCM return a tuple of 2 '\n",
       "                                        'elements:\\\\n                The first '\n",
       "                                        'element is a numpy np.ndarray, 32-bit '\n",
       "                                        'or 64-bit float, with shape '\n",
       "                                        '(channels, pixel height, pixel '\n",
       "                                        'width)\\\\n                The second '\n",
       "                                        'element is a '\n",
       "                                        'dictionary.\\\\n                    The '\n",
       "                                        'only required key is '\n",
       "                                        \"'masks'\\\\n                    The \"\n",
       "                                        \"'masks' key must map to a numpy \"\n",
       "                                        'np.ndarray, 64-bit integers, with '\n",
       "                                        'shape (classes, pixel height, pixel '\n",
       "                                        'width)\\\\n                    In this '\n",
       "                                        'case the classes are background and '\n",
       "                                        'building (just 2 '\n",
       "                                        'classes)\\\\n                    For '\n",
       "                                        'the background class, pixel locations '\n",
       "                                        'that are background should be set to '\n",
       "                                        '1, otherwise 0\\\\n                    '\n",
       "                                        'For the building class, pixel '\n",
       "                                        'locations that are buildings should '\n",
       "                                        'be set to 1, otherwise '\n",
       "                                        '0\\\\n                    Image values '\n",
       "                                        'in the numpy ndarray should be '\n",
       "                                        'normalized to a range from 0.0 to '\n",
       "                                        '1.0\\\\n\\\\n            Other '\n",
       "                                        'requirements:\\\\n                Image '\n",
       "                                        'Width must be the same as '\n",
       "                                        'Segmentation Mask '\n",
       "                                        'Width\\\\n                Image Height '\n",
       "                                        'must be the same as Segmentation Mask '\n",
       "                                        'Height\\\\n\\\\n                If no '\n",
       "                                        'features are present. the mask should '\n",
       "                                        'still exist but take on default '\n",
       "                                        'values, eg\\\\n                    '\n",
       "                                        'background class all '\n",
       "                                        'ones\\\\n                    building '\n",
       "                                        'class all zeros\\\\n                    '\n",
       "                                        'other constraints are still '\n",
       "                                        'enforced\\\\n\\\\n            '\n",
       "                                        'Args:\\\\n                index into '\n",
       "                                        'the dataset to '\n",
       "                                        'sample\\\\n\\\\n            '\n",
       "                                        'Returns:\\\\n                The '\n",
       "                                        'dataset example at a given index in '\n",
       "                                        'the form of a tuple '\n",
       "                                        'of\\\\n                np.ndarray and '\n",
       "                                        'dictionary of string key mapped to '\n",
       "                                        'np.ndarrays\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n\\\\n            # index '\n",
       "                                        'into folders\\\\n            '\n",
       "                                        'example_file = '\n",
       "                                        'self.links[idx]\\\\n\\\\n            # '\n",
       "                                        'construct the known corresponding '\n",
       "                                        'label folder name\\\\n            '\n",
       "                                        'label_folder = '\n",
       "                                        'f\\\\\"{os.path.dirname(example_file)}-labels\\\\\"\\\\n\\\\n            '\n",
       "                                        '# construct the relative path to the '\n",
       "                                        '\\\\\"stac.json file\\\\\"\\\\n            '\n",
       "                                        'label_file = '\n",
       "                                        'os.path.join(label_folder, '\n",
       "                                        \"'stac.json')\\\\n\\\\n            with \"\n",
       "                                        'open(os.path.join(self.collection_dir, '\n",
       "                                        \"example_file), 'r') as \"\n",
       "                                        'f:\\\\n                example_json = '\n",
       "                                        'json.load(f)\\\\n\\\\n            # '\n",
       "                                        'construct the path to the image '\n",
       "                                        'file\\\\n            image_file = '\n",
       "                                        'os.path.join(self.collection_dir, '\n",
       "                                        'os.path.dirname(example_file), '\n",
       "                                        'example_json[\\\\\"assets\\\\\"][\\\\\"RGB\\\\\"][\\\\\"href\\\\\"])\\\\n\\\\n            '\n",
       "                                        'with '\n",
       "                                        'open(os.path.join(self.collection_dir, '\n",
       "                                        \"label_file), 'r') as \"\n",
       "                                        'f:\\\\n                labels_json = '\n",
       "                                        'json.load(f)\\\\n\\\\n            # '\n",
       "                                        'construct the paths to the labels '\n",
       "                                        'file\\\\n            label_file = '\n",
       "                                        'os.path.join(self.collection_dir, '\n",
       "                                        'label_folder, '\n",
       "                                        'labels_json[\\\\\"assets\\\\\"][\\\\\"labels\\\\\"][\\\\\"href\\\\\"])\\\\n\\\\n            '\n",
       "                                        '# load the .tif image from '\n",
       "                                        'disk\\\\n            pil_img = '\n",
       "                                        'Image.open(image_file)\\\\n\\\\n            '\n",
       "                                        '# convert the PIL image to a numpy '\n",
       "                                        'array\\\\n            img = '\n",
       "                                        'np.array(pil_img)\\\\n\\\\n            # '\n",
       "                                        'normalize from 0.0 to '\n",
       "                                        '1.0\\\\n            img = (img - '\n",
       "                                        'img.min()) / (img.max() - '\n",
       "                                        'img.min())\\\\n\\\\n            # open '\n",
       "                                        'with fiona to get features for mask - '\n",
       "                                        'this represnts the '\n",
       "                                        'buildings\\\\n            with '\n",
       "                                        \"fiona.open(label_file, 'r') as \"\n",
       "                                        'f:\\\\n                features = '\n",
       "                                        '[feature[\\\\\"geometry\\\\\"] for feature '\n",
       "                                        'in f]\\\\n\\\\n            # create the '\n",
       "                                        'rasterizer object based on the image '\n",
       "                                        'data\\\\n            rds = '\n",
       "                                        'rioxarray.open_rasterio(image_file).isel(band=0)\\\\n\\\\n            '\n",
       "                                        '# get the geojson data\\\\n            '\n",
       "                                        'with open(label_file) as '\n",
       "                                        'igj:\\\\n                data = '\n",
       "                                        'geojson.load(igj)\\\\n\\\\n            # '\n",
       "                                        'binary crossentropy requires masks of '\n",
       "                                        'shape (2, height, '\n",
       "                                        'width)\\\\n            # the first '\n",
       "                                        'channel represnts classes; '\n",
       "                                        '0=background, '\n",
       "                                        '1=building\\\\n            mask = '\n",
       "                                        'np.zeros((2, '\n",
       "                                        '*img.shape[0:2])).astype(np.int64)\\\\n            '\n",
       "                                        'mask[0,:,:] = np.ones((1, '\n",
       "                                        '*img.shape[0:2])) # background by '\n",
       "                                        'default\\\\n\\\\n            # if this '\n",
       "                                        'training/validation example has '\n",
       "                                        'features (building '\n",
       "                                        'masks)\\\\n            if len(features) '\n",
       "                                        '\\\\u003e 0:\\\\n\\\\n                # get '\n",
       "                                        'the mask - binary cross '\n",
       "                                        'entropy\\\\n                rds = '\n",
       "                                        'rds.rio.clip(features, '\n",
       "                                        'data[\\\\\"crs\\\\\"][\\\\\"properties\\\\\"][\\\\\"name\\\\\"], '\n",
       "                                        'drop=False)\\\\n                nprds = '\n",
       "                                        'np.array(rds)\\\\n\\\\n                '\n",
       "                                        'mask[0, :, :] = '\n",
       "                                        'np.where((nprds)\\\\u003e0.5, 0, '\n",
       "                                        'mask[0, :, :])\\\\n                '\n",
       "                                        'mask[1, :, :] = '\n",
       "                                        'np.where(nprds\\\\u003e0.5, 1, mask[1, '\n",
       "                                        ':, :])\\\\n\\\\n            # if the '\n",
       "                                        'example did not have features, leave '\n",
       "                                        'the images and masks as they '\n",
       "                                        'were\\\\n\\\\n            # channels, '\n",
       "                                        'height, width\\\\n            img = '\n",
       "                                        'np.transpose(img,  (2, 0, '\n",
       "                                        '1))\\\\n\\\\n            # clip both '\n",
       "                                        'masks and images to ensure they are '\n",
       "                                        'the same size\\\\n            # '\n",
       "                                        'otherwise CCM / Most Conv networks '\n",
       "                                        'will not accept\\\\n            '\n",
       "                                        'min_height = min(img.shape[1], '\n",
       "                                        'mask.shape[1])\\\\n            '\n",
       "                                        'min_width  = min(img.shape[2], '\n",
       "                                        'mask.shape[2])\\\\n            img = '\n",
       "                                        'img[:, :min_height, '\n",
       "                                        ':min_width]\\\\n            mask = '\n",
       "                                        'mask[:, :min_height, '\n",
       "                                        ':min_width]\\\\n            mask = '\n",
       "                                        'np.expand_dims(np.argmax(mask, '\n",
       "                                        'axis=0), axis=0)\\\\n\\\\n            # '\n",
       "                                        'CCM vision models expect targets to '\n",
       "                                        'be in a dictionary \\\\n            # '\n",
       "                                        'other keys for other types of '\n",
       "                                        'computer vision problems '\n",
       "                                        \"include\\\\n            # 'boxes' and \"\n",
       "                                        \"'labels'. UNet does not require \"\n",
       "                                        'those\\\\n            return img, '\n",
       "                                        \"{'masks': mask}\\\\n\\\\n    # \"\n",
       "                                        'Instantiate the Dataloader\\\\n    '\n",
       "                                        'DATASET_PATH = '\n",
       "                                        '\\\\\"/data/V1/sn1_AOI_1_RIO/sn1_AOI_1_RIO/sn1_AOI_1_RIO/\\\\\"\\\\n    '\n",
       "                                        'PATH_TO_COLLECTION_FILE=os.path.join(DATASET_PATH, '\n",
       "                                        \"'collection.json')\\\\n    dataset = \"\n",
       "                                        'SpaceNetDataset(PATH_TO_COLLECTION_FILE)\\\\n\\\\n    '\n",
       "                                        'TRAIN_SPLIT = 0.7\\\\n    TEST_SPLIT = '\n",
       "                                        '0.3\\\\n\\\\n    print(f\\\\\"TRAINING SPLIT '\n",
       "                                        'STARTED\\\\\")\\\\n\\\\n    test_dataset, '\n",
       "                                        'train_dataset = '\n",
       "                                        'torch.utils.data.random_split(\\\\n        '\n",
       "                                        'dataset, \\\\n        '\n",
       "                                        '[math.floor(TEST_SPLIT*len(dataset)), '\n",
       "                                        'math.ceil(TRAIN_SPLIT*len(dataset)) '\n",
       "                                        '],\\\\n        '\n",
       "                                        'generator=torch.Generator().manual_seed(1234)\\\\n    '\n",
       "                                        ')\\\\n\\\\n    print(f\\\\\"TRAINING SPLIT '\n",
       "                                        'FINISHED\\\\\")\\\\n\\\\n    # instantiate '\n",
       "                                        'UNet Model Configuration\\\\n    config '\n",
       "                                        '= ModelConfiguration()\\\\n\\\\n    # '\n",
       "                                        'instantiate UNet Vision Model '\n",
       "                                        'Configuration\\\\n    model_config = '\n",
       "                                        'VisionModelConfiguration(\\\\n        '\n",
       "                                        'input_shape=(480,480),\\\\n        '\n",
       "                                        'n_classes=2,\\\\n        '\n",
       "                                        'input_channels=3,\\\\n        '\n",
       "                                        'batch_size=6,\\\\n        '\n",
       "                                        'learning_rate=1e-4,\\\\n        '\n",
       "                                        'validation_split=0.3,\\\\n        '\n",
       "                                        'training_epochs=11,\\\\n        '\n",
       "                                        'layers_model_configuration=config,\\\\n    '\n",
       "                                        ')\\\\n    # ensure we allow for the '\n",
       "                                        'background class and building '\n",
       "                                        'class\\\\n    # RGB    \\\\n    # during '\n",
       "                                        'testing x% of the training dataset '\n",
       "                                        'will be reserved for '\n",
       "                                        'validation\\\\n\\\\n    # Instantiate '\n",
       "                                        'UNet\\\\n    model = '\n",
       "                                        'Model(model_config)\\\\n\\\\n        # if '\n",
       "                                        'using pretrained weights, Images '\n",
       "                                        'should be renormalized according to '\n",
       "                                        \"pytorch's specification:\\\\n        \"\n",
       "                                        '#    '\n",
       "                                        'torchvision.transforms.Normalize(mean=[0.485, '\n",
       "                                        '0.456, 0.406],\\\\n        '\n",
       "                                        '#                                     '\n",
       "                                        'std=[0.229, 0.224, 0.225])\\\\n        '\n",
       "                                        '# see '\n",
       "                                        'https://gitlab.us.lmco.com/overwatch/cognitive-modules/classification/-/blob/master/examples/jupyter_notebooks/supervised_examples/deep_learning_examples/inception_v3_classifier_example.ipynb\\\\n        '\n",
       "                                        '#         Create Classes and Labels '\n",
       "                                        'from Dataset \\\\n\\\\n    nowstr = '\n",
       "                                        \"datetime.datetime.now().strftime('%m%d%Y_%H%M%S')\\\\n    \"\n",
       "                                        'model_path = '\n",
       "                                        \"f'./mnt/space_net_models/trained_spacenet_{nowstr}.pt'\\\\n    \"\n",
       "                                        'print(f\\\\\"training new model: '\n",
       "                                        '{model_path}\\\\\")\\\\n    '\n",
       "                                        'model_save_path = model_path\\\\n    '\n",
       "                                        'checkpoint_path = '\n",
       "                                        \"'./mnt/space_net_models/'\\\\n    \"\n",
       "                                        'os.makedirs(os.path.dirname(model_path), '\n",
       "                                        'exist_ok=True)\\\\n\\\\n    # train the '\n",
       "                                        'model!\\\\n    results = '\n",
       "                                        'model.fit(train_dataset, '\n",
       "                                        'verbose=True, '\n",
       "                                        'callbacks=[CheckpointCallback(checkpoint_path)])\\\\n\\\\n    '\n",
       "                                        '# save the trained model for the '\n",
       "                                        'epochs configured\\\\n    '\n",
       "                                        'model.save_model(model_save_path)\\\\n    '\n",
       "                                        'print(f\\\\\"saving model to: '\n",
       "                                        '{model_save_path} \\\\\\\\n\\\\\") \\\\n\\\\n    '\n",
       "                                        '# load the trained model\\\\n    '\n",
       "                                        'model.load_model(model_save_path)\\\\n\\\\n    '\n",
       "                                        '# load a test example\\\\n    img, mask '\n",
       "                                        '= test_dataset[ random.randint(0, '\n",
       "                                        'len(test_dataset)) ]\\\\n\\\\n    # run '\n",
       "                                        'model inference\\\\n    results = '\n",
       "                                        'model.infer([img])\\\\n\\\\n    '\n",
       "                                        'result_mask = '\n",
       "                                        \"results[0]['masks']\\\\n\\\\n    \"\n",
       "                                        'result_mask = (result_mask - '\n",
       "                                        'result_mask.min()) / '\n",
       "                                        '(result_mask.max()-result_mask.min())\\\\n\\\\n    '\n",
       "                                        'print(\\\\\"******** Inference Results '\n",
       "                                        '********\\\\\")\\\\n    print(f\\\\\"Overall '\n",
       "                                        'minimum prediction confidence = '\n",
       "                                        '{result_mask.min()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Overall maximum prediction '\n",
       "                                        'confidence = '\n",
       "                                        '{result_mask.max()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Overall mean prediction '\n",
       "                                        'confidence = {result_mask.mean()} '\n",
       "                                        '\\\\\\\\n\\\\\")\\\\n\\\\n    print(f\\\\\"Minimum '\n",
       "                                        'Building prediction confidence = '\n",
       "                                        '{result_mask[1,:,:].min()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Maximum Building prediction '\n",
       "                                        'confidence = '\n",
       "                                        '{result_mask[1,:,:].max()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Mean Building prediction '\n",
       "                                        'confidence = '\n",
       "                                        '{result_mask[1,:,:].mean()} '\n",
       "                                        '\\\\\\\\n\\\\\")\\\\n\\\\n    print(f\\\\\"Minimum '\n",
       "                                        'Background prediction confidence = '\n",
       "                                        '{result_mask[0,:,:].min()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Maximum Background '\n",
       "                                        'prediction confidence = '\n",
       "                                        '{result_mask[0,:,:].max()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Mean Background prediction '\n",
       "                                        'confidence = '\n",
       "                                        '{result_mask[0,:,:].mean()}\\\\\")\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Predict', \"\n",
       "                                        \"description='')\\\\n_parsed_args = \"\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'predict(**_parsed_args)\\\\n\"],\"env\":[{\"name\":\"PIP_EXTRA_INDEX_URL\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"nexus-config\",\"key\":\"PIP_EXTRA_INDEX_URL\"}}},{\"name\":\"PIP_INDEX_URL\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"nexus-config\",\"key\":\"PIP_INDEX_URL\"}}}],\"resources\":{\"limits\":{\"nvidia.com/gpu\":\"8\"}},\"volumeMounts\":[{\"name\":\"pvolume-e08f34d8bcb983a9b9b9689d664304a9fe46292eb114fc9f83031d4\",\"mountPath\":\"/data\"}]}],\"volumes\":[{\"name\":\"pvolume-e08f34d8bcb983a9b9b9689d664304a9fe46292eb114fc9f83031d4\",\"persistentVolumeClaim\":{\"claimName\":\"spacenet-data\"}}]},\"runAfter\":[\"view-data\"],\"timeout\":\"8760h0m0s\"}]},\"timeout\":\"8760h0m0s\"},\"status\":{}}'},\n",
       " 'resource_references': [{'key': {'id': '6e48a603-ab1a-4e36-823e-db8c7a508250',\n",
       "                                  'type': 'EXPERIMENT'},\n",
       "                          'name': 'RMS ET Intern Project',\n",
       "                          'relationship': 'OWNER'},\n",
       "                         {'key': {'id': '890e794c-da54-4d24-ab59-453732c80203',\n",
       "                                  'type': 'PIPELINE_VERSION'},\n",
       "                          'name': 'tf_spacenet_cv_classify_pipeline-e426805_version_at_2022-07-20T14:40:15.661785Z',\n",
       "                          'relationship': 'CREATOR'}],\n",
       " 'scheduled_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
       " 'service_account': 'default-editor',\n",
       " 'status': None,\n",
       " 'storage_state': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = kfp_tekton.TektonClient(\n",
    "    host=f\"{KUBEFLOW_PUBLIC_ENDPOINT_URL}/pipeline\",\n",
    "    ssl_ca_cert=\"/etc/ssl/certs/ca-certificates.crt\",\n",
    "    cookies=SESSION_COOKIE\n",
    ")\n",
    "\n",
    "try:\n",
    "    experiment = client.get_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "except ValueError:\n",
    "    experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "kfp_tekton.compiler._op_to_template.RESOURCE_OP_IMAGE='lmregistry.us.lmco.com/ext.hub.docker.com/aipipeline/kubectl-wrapper:0.8.0'\n",
    "kfp_tekton.compiler.TektonCompiler().compile(rms_et_basic_pipeline, PIPELINE_PACKAGE)\n",
    "pipeline_id = client.get_pipeline_id(PIPELINE_NAME)\n",
    "\n",
    "if not pipeline_id:\n",
    "    # upload the package to Kubeflow\n",
    "    r = client.upload_pipeline(PIPELINE_PACKAGE, pipeline_name=PIPELINE_NAME)\n",
    "\n",
    "    # update the pipeline id\n",
    "    pipeline_id = r.id\n",
    "\n",
    "now = datetime.datetime.now().isoformat()\n",
    "pipeline_versionName = f\"{PIPELINE_NAME}_version_at_{now}Z\"\n",
    "version = client.pipeline_uploads.upload_pipeline_version(uploadfile=PIPELINE_PACKAGE, name=pipeline_versionName, pipelineid=pipeline_id)\n",
    "\n",
    "client.run_pipeline(experiment.id, f\"{PIPELINE_NAME} {now}\", pipeline_id=pipeline_id, version_id=version.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "33264e53a25ce865e784f7564913a735150180acd61f94069a0938fa0948b294"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
